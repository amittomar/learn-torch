{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30f8f40e-9fe9-4dc7-98b9-e43d1da19930",
   "metadata": {},
   "source": [
    "### Review classification using Pre transformer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7211a3e-cbff-4d2a-a5a9-0e6c9727bf16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f61f393-f716-4cfb-a17b-c9aff9c9f6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import continue, import Transformer\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf0cd995-e579-4eda-bf1a-6cb328f2c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set Random Seed\n",
    "torch.manual_seed(42)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "108321e9-f555-40a2-8779-2c9c22658450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1  OK... so... I really like Kris Kristofferson a...          0\n",
       "2  ***SPOILER*** Do not read this, if you think a...          0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Download data from github\n",
    "url = \"https://github.com/rasbt/machine-learning-book/raw/main/ch08/movie_data.csv.gz\"\n",
    "filename = url.split(\"/\")[-1]\n",
    "\n",
    "with open(filename, 'wb') as f:\n",
    "    r = requests.get(url)\n",
    "    f.write(r.content)\n",
    "\n",
    "with gzip.open(filename, 'rb') as f_in:\n",
    "    with open('movie_data.csv', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in,f_out)\n",
    "\n",
    "# Reading the csv to dataframe\n",
    "df = pd.read_csv('movie_data.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f38a9d7-0416-4029-a275-15bb49c19350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of                                                   review  sentiment\n",
       "0      In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1      OK... so... I really like Kris Kristofferson a...          0\n",
       "2      ***SPOILER*** Do not read this, if you think a...          0\n",
       "3      hi for all the people who have seen this wonde...          1\n",
       "4      I recently bought the DVD, forgetting just how...          0\n",
       "...                                                  ...        ...\n",
       "49995  OK, lets start with the best. the building. al...          0\n",
       "49996  The British 'heritage film' industry is out of...          0\n",
       "49997  I don't even know where to begin on this one. ...          0\n",
       "49998  Richard Tyler is a little boy who is scared of...          0\n",
       "49999  I waited long to watch this movie. Also becaus...          1\n",
       "\n",
       "[50000 rows x 2 columns]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the dataset\n",
    "df.shape\n",
    "df.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0da053-b4b8-4956-a6f2-e9c7cd4276a8",
   "metadata": {},
   "source": [
    "## Create Train validation and test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03abb5e9-cf98-4378-b841-fa0bd1c01253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (35000,) y_train shape : (35000,) \n",
      "X_val shape : (5000,) y_val shape : (5000,) \n",
      "X_test shape : (10000,) y_test shape : (10000,) \n"
     ]
    }
   ],
   "source": [
    "X_train = df.iloc[:35000]['review'].values\n",
    "y_train = df.iloc[:35000]['sentiment'].values\n",
    "\n",
    "X_val = df.iloc[35000:40000]['review'].values\n",
    "y_val = df.iloc[35000:40000]['sentiment'].values\n",
    "\n",
    "X_test = df.iloc[40000:]['review'].values\n",
    "y_test = df.iloc[40000:]['sentiment'].values\n",
    "\n",
    "print(f\"X_train shape : {X_train.shape} y_train shape : {y_train.shape} \")\n",
    "print(f\"X_val shape : {X_val.shape} y_val shape : {y_val.shape} \")\n",
    "print(f\"X_test shape : {X_test.shape} y_test shape : {y_test.shape} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeacb137-7454-49ae-80cb-9fcd4a9a4872",
   "metadata": {},
   "source": [
    "## Tokennize the datset using Dataset api from torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1528905-c838-4550-a5e1-507aa33e7ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf68bdbfe81438188e76af89eda9178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12e22d2b7944f10ac3cf99705c282d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fd08c18aaf4d8eaf15b89fd6b75db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46d2f2136b3447e928b4428400d9139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "X_train_encoding = tokenizer(list(X_train), truncation=True, padding=True)\n",
    "X_val_encoding = tokenizer(list(X_val), truncation=True, padding=True)\n",
    "X_test_encoding = tokenizer(list(X_test), truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f380c69d-b0ad-42c9-b906-18fbe0008d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Dataset using torch.util.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea4a4425-4c92-4ca2-919d-ea1b54a3e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ImdbDataSet(Dataset):\n",
    "    \n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key : torch.tensor(val[idx]) for key,val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70555e3-598c-4b73-bbd6-793f3524f50a",
   "metadata": {},
   "source": [
    "### create Dataset from using above class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e2fa3fc2-af34-4ad2-9a5e-ae43cc79c3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = ImdbDataSet(X_train_encoding,y_train)\n",
    "val_dataset = ImdbDataSet(X_val_encoding, y_val)\n",
    "test_dataset = ImdbDataSet(X_test_encoding, y_val)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ed1be8-0e9a-48c3-82c6-dd9d2d55648a",
   "metadata": {},
   "source": [
    "## Create loaders for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e1475849-b8f5-4d45-9200-e7339c0e0a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d877b7-eb66-4a97-9644-cd8b3dd4e900",
   "metadata": {},
   "source": [
    "### Loading and FineTuning a Pretrained BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b809c735-b01c-428b-8000-64c5507bebb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "be2da9eb-62d4-4c2b-9466-49538b377537",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Optimizer and Loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8b87b393-1dbf-420f-8ee0-0fec44100377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "def compute_accuracy(model: nn.modules, data_loader : DataLoader, device):\n",
    "    with torch.inference_mode():\n",
    "        correct_pred, num_examples = 0,0\n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "            ## prepeare data\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            \n",
    "            attention_masks = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids,attention_masks)\n",
    "            \n",
    "            ## fetch logits\n",
    "            logits = outputs['logits']\n",
    "            ## \n",
    "            predicted_labels = torch.argmax(logits,1)\n",
    "            num_examples += labels.size(0)\n",
    "            correct_pred += (predicted_labels == labels).sum()\n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ececd35-c7c7-4276-bdf5-0b22976cfaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3831c52-2af9-4d85-a462-00931292a073",
   "metadata": {},
   "source": [
    "### Trainig loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a4a52-b0f2-460a-8904-c3aa8f8ff8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0/3 | Batch : 0/ 1094 | loss : 0.942276\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    #Traing mode\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        ## Prepare data\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask  = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(input_ids,attention_mask=attention_mask,labels=labels)\n",
    "        \n",
    "        logits = outputs['logits']\n",
    "        # get loss\n",
    "        loss = outputs['loss']\n",
    "        \n",
    "        # Zero grad and backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "        \n",
    "        ## Some logging for visibility during training\n",
    "        \n",
    "        \n",
    "        if batch_idx % 250 == 0:\n",
    "            print(f\"Epoch : {epoch}/{EPOCHS} | Batch : {batch_idx}/ {len(train_loader)} | loss : {loss:4f}\")\n",
    "        \n",
    "        \n",
    "        ## evaluate the model\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            print(f\"Training accuracy : {compute_accuracy(model,train_loader,device):.2f}%\")\n",
    "            print(f\"validation accuracy : {compute_accuracy(model,valid_loader,device):.2f}%\")\n",
    "            print(f\"Testing accuracy : {compute_accuracy(model,test_loader,device):.2f}%\")\n",
    "    print(f\"Time elapsed : {(time.time()- start_time)/60:.2f} mins\")\n",
    "\n",
    "print(f\"Total traning time : {(time.time() - start_time)/60: .2f} mins\")\n",
    "print(f\"TEst accuracy : {compute_accuracy(model, test_loader, device=device): .2f}%\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fec5bd-f436-495a-ab73-9a3d1774f493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f7b6ba-845f-4f0b-8a83-ac6f95d7ae67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
